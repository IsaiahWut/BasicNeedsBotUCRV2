# ğŸ•’ Scheduled Web Scraper

This project is a Python web scraper that runs automatically every day at 11:17 AM, using GitHub Actions as the scheduler.
It includes built-in logic to ensure it only runs twice per week (Sunday â†’ Sunday) to avoid overloading the target website.


## ğŸš€ Features

    â° Automated Scheduling â€” Runs daily at 11:17 AM via GitHub Actions cron jobs.
    
    ğŸ§  Weekly Run Limit â€” The scraper will only run a maximum of 2 times per week.
    
    â˜ï¸ Cloud-Based â€” Runs on GitHubâ€™s cloud runner, so your local machine doesnâ€™t need to be on.
    
    ğŸ“ Logging â€” Keeps a record of past runs in a JSON file for easy tracking.
    
    ğŸ•µï¸ Web Scraping â€” Extracts and processes data from your target website automatically.


## ğŸ“¦ Project Structure
``` 
    .
    â”œâ”€â”€ scraper.py              # Main script that performs the scraping task
    â”œâ”€â”€ run_tracker.json        # Keeps track of run timestamps for weekly limit
    â”œâ”€â”€ .github/
    â”‚   â””â”€â”€ workflows/
    â”‚       â””â”€â”€ schedule.yml    # GitHub Actions workflow file for scheduling
    â””â”€â”€ README.md               # Project documentation
```

